This thesis investigates the impact of small-scale datasets and hyperparameter variations on the embedding space structure and zero-shot classification performance of CLIP-like models. Using systematic experimentation and comparisons with the pretrained CLIP ViT-B/32 model, the study identifies key challenges and opportunities for training under resource-constrained conditions. While the pretrained model achieved a top-1 accuracy of 87.32%, custom-trained models reached a maximum of 28.63% when trained on the Flickr 30k dataset. Embedding space analysis revealed significant structural differences, with the pretrained model producing well-differentiated embeddings, while custom models exhibited less nuanced structures. Training on the larger Flickr 30k dataset resulted in more cohesive embeddings compared to the smaller Flickr 8k dataset, but performance remained constrained by dataset size and the manual, iterative hyperparameter selection process.

The study highlights key constraints, including reduced embedding dimensionality, smaller batch sizes, and dataset misalignment, which impacted generalization capabilities. Despite these challenges, the findings demonstrate the potential for improving performance through more systematic hyperparameter optimization and tailored training configurations. Proposed future directions include restoring higher-dimensional embeddings, adopting automated hyperparameter search strategies, and incorporating multi-label evaluation metrics to enhance robustness and adaptability.

This research advances understanding of how dataset size and hyperparameters influence zero-shot learning models and provides actionable insights for enhancing their performance, particularly in scenarios with limited data and computational resources.
